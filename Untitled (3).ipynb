{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab5fcb1-bb3e-4755-aa1d-46b2583324f6",
   "metadata": {},
   "source": [
    "##Q1. What is the purpose of grid search cv in machine learning, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f3832-4826-4c41-8e68-07b2aa7d27fe",
   "metadata": {},
   "source": [
    " GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid. It's essentially a cross-validation technique. The model as well as the parameters must be entered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb0540-544a-45c6-8f06-854592ef489b",
   "metadata": {},
   "source": [
    "##Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose\n",
    "one over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7f12a9-d41c-4b56-a009-dd219ea2ef37",
   "metadata": {},
   "source": [
    "Random Search CV prioritizes exploration by randomly sampling combinations, whereas Grid Search CV exhaustively evaluates all combinations. The former allows for wider exploration, while the latter guarantees a thorough search within the specified grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f03a17-3a97-4fd1-9eb2-6ab8417192a4",
   "metadata": {},
   "source": [
    "##Q3. What is data leakage, and why is it a problem in machine learning? Provide an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434c93db-f367-4db0-abb1-19712a67e512",
   "metadata": {},
   "source": [
    "In short, data leakage in machine learning is a term used to describe a case where the data used to train an algorithm includes unexpected additional information about the subject it's evaluating. Essentially, it happens when information from outside a desired training data set helps to create a model\n",
    "Data leakage occurs when sensitive data gets unintentionally exposed to the public in transit, at rest, or in use. Here are common examples: Data exposed in transit â€” Data transmitted via emails, API calls, chat rooms, and other communications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e58ab-7286-4ab7-9984-1bc81aa629d8",
   "metadata": {},
   "source": [
    "##Q4. How can you prevent data leakage when building a machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b462835-417d-482a-9bc1-23eaa909bf07",
   "metadata": {},
   "source": [
    "You can minimize data leakage in machine learning in many different ways. You can start by partitioning your data into training and test subsets before engaging in any preprocessing. Maintain the chronological sequence in time series data and avoid using subsequent data for predictions related to earlier time points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b489f3-4a5a-4afa-8ddb-0d69acb8c177",
   "metadata": {},
   "source": [
    "##Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc27d47-2669-41e2-ab60-090f4248c949",
   "metadata": {},
   "source": [
    "A confusion matrix is a performance evaluation tool in machine learning, representing the accuracy of a classification model. It displays the number of true positives, true negatives, false positives, and false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e5ac6-9f0b-46c8-8327-0a53bc54d28e",
   "metadata": {},
   "source": [
    "##Q6. Explain the difference between precision and recall in the context of a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e72e8-baab-472c-a408-4aa641ac7fc3",
   "metadata": {},
   "source": [
    "Precision and recall are two evaluation metrics used to measure the performance of a classifier in binary and multiclass classification problems. Precision measures the accuracy of positive predictions, while recall measures the completeness of positive predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ab1f77-0a9f-49b5-89f1-e7529244c1dc",
   "metadata": {},
   "source": [
    "##Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae6f6b5-c7f3-41ec-a6ad-eea39b7d3efa",
   "metadata": {},
   "source": [
    "True Positive (TP) - Your model predicted the positive class. ...\n",
    "True Negative (TN) - Your model correctly predicted the negative class. ...\n",
    "False Positive (FP) - Your model incorrectly predicted the positive class. ...\n",
    "False Negative (FN) - Your model incorrectly predicted the negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbcedf8-1420-4fa7-8934-cd3967239a96",
   "metadata": {},
   "source": [
    "##Q8. What are some common metrics that can be derived from a confusion matrix, and how are they\n",
    "calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e162c8-70e9-4a5f-946c-8ced268c179e",
   "metadata": {},
   "source": [
    "Accuracy. Accuracy is used to measure the performance of the model. ...\n",
    "Precision. Precision is a measure of how accurate a model's positive predictions are. ...\n",
    "Recall. ...\n",
    "F1-Score. ...\n",
    "Specificity: ...\n",
    "Type 1 and Type 2 error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aba7d3-324e-45cd-92a7-23e2d9206211",
   "metadata": {},
   "source": [
    "##Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e290e98-ad9a-4a99-99d2-acc04f8b1c53",
   "metadata": {},
   "source": [
    "The model's confusion matrix shows only one false negative and no false positives; the model correctly classifies every other data instance. Thus the model has an accuracy of 99%. Though ostensibly desirable, high accuracy is not in itself indicative of excellent model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af1432-8d66-48b3-b8d7-5b5dc226ccf8",
   "metadata": {},
   "source": [
    "##Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning\n",
    "model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71dce48-232f-4063-8f0f-fcee041f67ed",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
